import os
import re
import time
import threading
import uuid
import random
import logging
from urllib.parse import urlparse
from flask import current_app
from app.services.siliconflow_service import SiliconFlowService
from app.services.search_service import search_service

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ResearchProcess:
    """ç ”ç©¶è¿‡ç¨‹ç±»ï¼Œç”¨äºç®¡ç†å’Œè·Ÿè¸ªç ”ç©¶è¿‡ç¨‹"""
    
    def __init__(self, topic, requirements):
        self.topic = topic
        self.requirements = requirements
        self.status = "planning"  # planning, researching, analyzing, completed, error
        self.progress = 0
        self.plan = None
        self.current_step = None
        self.research_sites = []
        self.research_findings = []
        self.analysis_results = []
        self.source_contents = {}  # å­˜å‚¨æŠ“å–çš„ç½‘é¡µå†…å®¹
        self.search_queries = []  # å­˜å‚¨æœç´¢æŸ¥è¯¢
        self.research_steps = []  # å­˜å‚¨è¯¦ç»†çš„ç ”ç©¶æ­¥éª¤åŠå…¶è¿›åº¦å’Œç»“æœ
        self.current_step_index = 0  # å½“å‰æ‰§è¡Œåˆ°çš„æ­¥éª¤ç´¢å¼•
        self.report = None
        self.error = None
        self.process_id = str(int(time.time() * 1000))
        self.start_time = time.time()
        self.ai_service = SiliconFlowService()
        logger.info(f"åˆå§‹åŒ–ç¡…åŸºæµåŠ¨APIæœåŠ¡ç”¨äºç ”ç©¶è¿‡ç¨‹: {self.process_id}")
        
    def to_dict(self):
        """å°†ç ”ç©¶è¿‡ç¨‹è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "process_id": self.process_id,
            "topic": self.topic,
            "requirements": self.requirements,
            "status": self.status,
            "progress": self.progress,
            "plan": self.plan,
            "current_step": self.current_step,
            "current_step_index": self.current_step_index,
            "research_steps": self.research_steps,  # æ·»åŠ è¯¦ç»†çš„ç ”ç©¶æ­¥éª¤åˆ—è¡¨
            "research_sites": self.research_sites,
            "research_findings": self.research_findings[:15],  # å¢åŠ è¿”å›çš„å‘ç°æ•°é‡
            "analysis_results": self.analysis_results,
            "search_queries": self.search_queries[:5],  # è¿”å›çš„æŸ¥è¯¢æ•°é‡
            "report": self.report,
            "error": self.error,
            "elapsed_time": round(time.time() - self.start_time, 2)
        }

class ResearchService:
    """ç ”ç©¶æœåŠ¡ï¼Œç”¨äºç®¡ç†æ‰€æœ‰ç ”ç©¶è¿‡ç¨‹"""
    
    def __init__(self):
        self.research_processes = {}
        # ä¸å†é¢„å®šä¹‰ç½‘ç«™åˆ—è¡¨ï¼Œè€Œæ˜¯ä½¿ç”¨æœç´¢æœåŠ¡æ¥è·å–çœŸå®æ•°æ®
        logger.info("åˆå§‹åŒ–ç ”ç©¶æœåŠ¡ï¼Œä½¿ç”¨çœŸå®æ•°æ®æ¨¡å¼")
        
    def create_research_process(self, topic, requirements):
        """åˆ›å»ºæ–°çš„ç ”ç©¶è¿‡ç¨‹"""
        research_process = ResearchProcess(topic, requirements)
        self.research_processes[research_process.process_id] = research_process
        self._start_research_thread(research_process)
        return research_process.process_id
        
    def get_research_process(self, process_id):
        """è·å–ç ”ç©¶è¿‡ç¨‹"""
        return self.research_processes.get(process_id)
        
    def _start_research_thread(self, research_process):
        """å¯åŠ¨ç ”ç©¶è®¡åˆ’ç”Ÿæˆçº¿ç¨‹ï¼Œåªè´Ÿè´£ç”Ÿæˆè®¡åˆ’ï¼Œä¸æ‰§è¡Œå®Œæ•´ç ”ç©¶"""
        thread = threading.Thread(target=self._generate_research_plan, args=(research_process,))
        thread.daemon = True
        thread.start()
        
    def _generate_research_plan(self, process):
        """åªç”Ÿæˆç ”ç©¶è®¡åˆ’ï¼Œä¸æ‰§è¡Œå®Œæ•´ç ”ç©¶è¿‡ç¨‹"""
        try:
            # 1. ç”Ÿæˆç ”ç©¶è®¡åˆ’
            process.status = "planning"
            process.current_step = "ç”Ÿæˆç ”ç©¶è®¡åˆ’"
            
            try:
                process.plan = process.ai_service.generate_research_plan(
                    process.topic, process.requirements
                )
                logger.info("ç ”ç©¶è®¡åˆ’ç”ŸæˆæˆåŠŸ")
                process.progress = 20
            except Exception as e:
                logger.error(f"ç”Ÿæˆç ”ç©¶è®¡åˆ’æ—¶å‡ºé”™: {str(e)}")
                process.error = f"ç”Ÿæˆç ”ç©¶è®¡åˆ’æ—¶å‡ºé”™: {str(e)}"
                process.status = "error"
                return
                
            # 2. ç­‰å¾…ç”¨æˆ·ç¡®è®¤ç ”ç©¶è®¡åˆ’
            process.status = "waiting_confirmation"
            process.current_step = "ç­‰å¾…ç”¨æˆ·ç¡®è®¤ç ”ç©¶è®¡åˆ’"
            
            # åç»­çš„ç ”ç©¶æ‰§è¡Œæ­¥éª¤å°†åœ¨ç”¨æˆ·ç¡®è®¤åé€šè¿‡start_research_executionè§¦å‘
            
        except Exception as e:
            process.error = f"ç”Ÿæˆç ”ç©¶è®¡åˆ’è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            process.status = "error"
        
    def _conduct_research(self, process):
        """æŒ‰ç…§ç ”ç©¶è®¡åˆ’çš„æ¯ä¸ªæ­¥éª¤æ‰§è¡Œç ”ç©¶ï¼ˆä»…åœ¨ç”¨æˆ·ç¡®è®¤è®¡åˆ’åè¿›è¡Œï¼‰"""
        try:
            # ç¡®ä¿å½“å‰çŠ¶æ€æ­£ç¡®
            if process.status != "waiting_confirmation":
                logger.error(f"çŠ¶æ€é”™è¯¯ï¼Œæ— æ³•æ‰§è¡Œç ”ç©¶: {process.status}")
                return
                
            logger.info(f"ç”¨æˆ·å·²ç¡®è®¤ç ”ç©¶è®¡åˆ’ï¼Œå¼€å§‹æ‰§è¡Œç ”ç©¶: {process.process_id}")
            
            # 1. è§£æç ”ç©¶è®¡åˆ’ä¸­çš„æ­¥éª¤
            research_steps = self._parse_research_plan(process.plan)
            total_steps = len(research_steps)
            
            # åˆå§‹åŒ–ç ”ç©¶æ­¥éª¤æ•°æ®ç»“æ„
            process.research_steps = [
                {
                    "title": step["title"],
                    "description": step["description"],
                    "completed": False,
                    "search_results": [],
                    "findings": [],
                    "analysis": None
                }
                for step in research_steps
            ]
            
            # æ›´æ–°çŠ¶æ€ä¸ºç ”ç©¶ä¸­
            process.status = "researching"
            process.progress = 30
            
            # 2. é€æ­¥æ‰§è¡Œæ¯ä¸ªç ”ç©¶æ­¥éª¤
            for i, step in enumerate(research_steps):
                # æ›´æ–°å½“å‰æ­¥éª¤ç´¢å¼•å’ŒçŠ¶æ€
                process.current_step_index = i
                current_step_data = process.research_steps[i]
                step_title = step["title"]
                step_description = step["description"]
                
                process.current_step = f"æ­¥éª¤ {i+1}/{total_steps}: {step_title}"
                logger.info(f"æ‰§è¡Œç ”ç©¶æ­¥éª¤ {i+1}/{total_steps}: {step_title}")
                
                # ä¸ºè¯¥æ­¥éª¤ç”Ÿæˆæœç´¢æŸ¥è¯¢
                search_queries = self._generate_step_search_queries(step_title, step_description)
                logger.info(f"ä¸ºæ­¥éª¤ '{step_title}' ç”Ÿæˆäº† {len(search_queries)} ä¸ªæœç´¢æŸ¥è¯¢")
                
                # æ·»åŠ åˆ°æ–‡æ¡£ä¸­ä»¥ä¾¿å‰ç«¯æ˜¾ç¤º
                process.search_queries.extend(search_queries)
                
                # æ‰§è¡Œæœç´¢å¹¶æ”¶é›†æ•°æ®
                step_findings = []
                
                for query in search_queries:
                    process.current_step = f"æœç´¢: {query} (æ­¥éª¤ {i+1}/{total_steps})"
                    logger.info(f"æ‰§è¡Œæœç´¢æŸ¥è¯¢: {query}")
                    
                    # è°ƒç”¨çœŸå®æœç´¢æœåŠ¡
                    search_results = search_service.search(query)
                    logger.info(f"æŸ¥è¯¢ '{query}' è¿”å›äº† {len(search_results)} ä¸ªç»“æœ")
                    
                    # å°†ç½‘ç«™ä¿¡æ¯æ·»åŠ åˆ°ç ”ç©¶ç½‘ç«™åˆ—è¡¨ä¸­
                    for result in search_results:
                        site_info = {
                            "name": result["source"],
                            "url": result["link"],
                            "title": result["title"],
                            "snippet": result["snippet"],
                            "icon": result.get("source_icon", "ğŸ”")
                        }
                        
                        # æ·»åŠ åˆ°æ­¥éª¤çš„æœç´¢ç»“æœä¸­
                        if site_info not in current_step_data["search_results"]:
                            current_step_data["search_results"].append(site_info)
                        
                        # åŒæ—¶æ·»åŠ åˆ°æ€»çš„ç ”ç©¶ç½‘ç«™åˆ—è¡¨ä¸­
                        if site_info not in process.research_sites:
                            process.research_sites.append(site_info)
                    
                    # æå–ç½‘é¡µå†…å®¹
                    for result in search_results[:3]:  # æ¯ä¸ªæŸ¥è¯¢é€‰æ‹©3ä¸ªç»“æœæ·±å…¥åˆ†æ
                        try:
                            url = result["link"]
                            process.current_step = f"æŠ“å–ç½‘é¡µå†…å®¹: {result['source']} (æ­¥éª¤ {i+1})"
                            
                            # è·å–ç½‘é¡µå†…å®¹
                            content = search_service.fetch_content(url)
                            if not content:
                                continue
                                
                            # å­˜å‚¨ç½‘é¡µå†…å®¹
                            process.source_contents[url] = content
                            
                            # æå–ç›¸å…³ä¿¡æ¯
                            key_info = search_service.extract_key_information(content, query)
                        
                            # åªæœ‰å½“key_infoæœ‰æ•ˆä¸”ä¸ä¸ºNoneæ—¶æ‰åˆ›å»ºå‘ç°
                            if key_info:
                                # æ ¼å¼åŒ–å‘ç°å†…å®¹ï¼Œå¢å¼ºå¯è¯»æ€§
                                domain = urlparse(result['link']).netloc
                                finding = f"æ ¹æ®{result['source']}({domain})çš„æ•°æ®ï¼Œ{key_info}"
                                
                                # æ·»åŠ åˆ°æ­¥éª¤çš„å‘ç°ä¸­
                                if finding not in current_step_data["findings"]:
                                    current_step_data["findings"].append(finding)
                                    logger.info(f"æ·»åŠ æ–°çš„ç ”ç©¶å‘ç°: {finding[:100]}...")
                                    
                                # åŒæ—¶æ·»åŠ åˆ°æ€»çš„ç ”ç©¶å‘ç°ä¸­
                                if finding not in process.research_findings:
                                    process.research_findings.append(finding)
                                    step_findings.append(finding)
                            else:
                                logger.warning(f"æ— æ³•ä» {result['source']} æå–æœ‰æ•ˆä¿¡æ¯")
                                # è®°å½•æå–å¤±è´¥çš„ç½‘ç«™ä½†ä¸æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                        except Exception as e:
                            logger.error(f"è·å–ç½‘é¡µå†…å®¹æ—¶å‡ºé”™: {str(e)}")
                
                # ä½¿ç”¨LLMåˆ†æè¯¥æ­¥éª¤çš„ç»“æœ
                if step_findings:
                    process.current_step = f"åˆ†ææ­¥éª¤ {i+1} çš„å‘ç°: {step_title}"
                    step_analysis = process.ai_service.analyze_step_findings(
                        step_title, 
                        "\n".join(step_findings)
                    )
                    
                    # ä¿å­˜åˆ†æç»“æœ
                    current_step_data["analysis"] = step_analysis
                    process.analysis_results.append(f"**{step_title}**\n{step_analysis}")
                else:
                    # å¦‚æœæ²¡æœ‰å‘ç°ï¼Œä¹Ÿéœ€è¦æ·»åŠ ä¸€ä¸ªç©ºçš„åˆ†æç»“æœ
                    current_step_data["analysis"] = "æœªæ”¶é›†åˆ°è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æã€‚"
                    process.analysis_results.append(f"**{step_title}**\næœªæ”¶é›†åˆ°è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æã€‚")
                
                # æ ‡è®°æ­¥éª¤å®Œæˆ
                current_step_data["completed"] = True
                
                # æ›´æ–°è¿›åº¦
                process.progress = 30 + (i+1) * (50 / total_steps)
            
            # 3. ç”ŸæˆæŠ¥å‘Šé˜¶æ®µ
            process.status = "reporting"
            process.current_step = "ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"
            process.progress = 90
            
            try:
                # æ”¶é›†æ‰€æœ‰æ­¥éª¤çš„ç ”ç©¶å‘ç°å’Œåˆ†æç»“æœ
                findings_text = ""
                
                for i, step_data in enumerate(process.research_steps):
                    findings_text += f"## æ­¥éª¤ {i+1}: {step_data['title']}\n\n"
                    
                    # æ·»åŠ æ­¥éª¤æè¿°
                    findings_text += f"{step_data['description']}\n\n"
                    
                    # æ·»åŠ æœç´¢ç»“æœ
                    if step_data['search_results']:
                        findings_text += "### ç›¸å…³æ•°æ®æ¥æº\n\n"
                        for result in step_data['search_results'][:5]:
                            findings_text += f"- {result['title']} ({result['name']})\n"
                        findings_text += "\n"
                    
                    # æ·»åŠ ç ”ç©¶å‘ç°
                    if step_data['findings']:
                        findings_text += "### ä¸»è¦å‘ç°\n\n"
                        for finding in step_data['findings']:
                            findings_text += f"- {finding}\n"
                        findings_text += "\n"
                    
                    # æ·»åŠ åˆ†æç»“æœ
                    if step_data['analysis']:
                        findings_text += "### åˆ†æ\n\n"
                        findings_text += f"{step_data['analysis']}\n\n"
                    
                    findings_text += "---\n\n"
                
                # ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š
                logger.info("å¼€å§‹ç”Ÿæˆç ”ç©¶æŠ¥å‘Š")
                try:
                    # å°è¯•é€šè¿‡AIæœåŠ¡ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
                    process.report = process.ai_service.generate_research_report(
                        process.plan, findings_text
                    )
                    logger.info("ç ”ç©¶æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                except Exception as e:
                    # å¦‚æœAIæœåŠ¡å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆç”Ÿæˆä¸€ä¸ªç®€å•çš„ç ”ç©¶æŠ¥å‘Š
                    logger.warning(f"ä½¿ç”¨AIæœåŠ¡ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ")
                    
                    # åˆ›å»ºä¸€ä¸ªç»“æ„åŒ–çš„åŸºæœ¬æŠ¥å‘Š
                    process.report = self._generate_fallback_report(process.topic, findings_text)
                    logger.info("ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆç”ŸæˆæŠ¥å‘ŠæˆåŠŸ")
                
                # å®Œæˆç ”ç©¶
                process.progress = 100
                process.status = "completed"
                process.current_step = "ç ”ç©¶å®Œæˆ"
            except Exception as e:
                logger.error(f"ç”Ÿæˆç ”ç©¶æŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")
                process.error = f"ç”Ÿæˆç ”ç©¶æŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}"
                process.status = "error"
            
        except Exception as e:
            process.error = f"ç ”ç©¶è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            process.status = "error"
    
    def _generate_fallback_report(self, topic, findings_text):
        """ç”Ÿæˆå¤‡ç”¨ç ”ç©¶æŠ¥å‘Šï¼Œå½“AIæœåŠ¡æ— æ³•ç”ŸæˆæŠ¥å‘Šæ—¶ä½¿ç”¨"""
        from datetime import datetime
        
        logger.info(f"ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆä¸ºä¸»é¢˜ '{topic}' ç”Ÿæˆç ”ç©¶æŠ¥å‘Š")
        
        # ç”Ÿæˆç»“æ„åŒ–çš„æŠ¥å‘Š
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""# ç ”ç©¶æŠ¥å‘Š: {topic}

## æ¦‚è¿°

æœ¬æŠ¥å‘Šæ±‡æ€»äº†å…³äºâ€œ{topic}â€çš„ç ”ç©¶å‘ç°ã€‚ç”±äºç³»ç»Ÿè´Ÿè½½è¿‡é«˜ï¼Œæœ¬æŠ¥å‘Šä½¿ç”¨å¤‡ç”¨ç”Ÿæˆç³»ç»Ÿåˆ›å»ºã€‚

## ç ”ç©¶æ–¹æ³•

æœ¬ç ”ç©¶é€šè¿‡å¤šä¸ªç½‘ç»œæ•°æ®æºæ”¶é›†ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨ç»“æ„åŒ–æ–¹æ³•æ±‡æ€»å…³é”®å‘ç°ã€‚

## ç ”ç©¶ä¸»ä½“

{findings_text}

## æ€»ç»“

ä¸Šè¿°ä¿¡æ¯æä¾›äº†å…³äºâ€œ{topic}â€çš„å¤šè§’åº¦è§‚ç‚¹ã€‚å»ºè®®è¿›ä¸€æ­¥æ·±å…¥åˆ†æå„é¡¹å‘ç°ï¼Œä»¥å¾—å‡ºæ›´å…¨é¢çš„ç»“è®ºã€‚

---
æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {current_time}
"""
        
        logger.info("å¤‡ç”¨æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        return report
        
    def start_research_execution(self, process_id):
        """å¼€å§‹æ‰§è¡Œç ”ç©¶ï¼ˆåœ¨ç”¨æˆ·ç¡®è®¤è®¡åˆ’åï¼‰"""
        process = self.get_research_process(process_id)
        if not process:
            logger.error(f"æ— æ³•æ‰¾åˆ°ç ”ç©¶è¿›ç¨‹: {process_id}")
            return False
            
        if process.status != "waiting_confirmation":
            logger.error(f"ç ”ç©¶è¿›ç¨‹çŠ¶æ€ä¸æ­£ç¡®ï¼Œæ— æ³•æ‰§è¡Œ: {process.status}")
            return False
            
        # å¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹æ¥æ‰§è¡Œç ”ç©¶
        logger.info(f"å¼€å§‹æ‰§è¡Œç ”ç©¶è¿‡ç¨‹: {process_id}")
        thread = threading.Thread(target=self._conduct_research, args=(process,))
        thread.daemon = True
        thread.start()
        return True
    
    def _parse_research_plan(self, plan):
        """ä»ç ”ç©¶è®¡åˆ’ä¸­è§£æå‡ºå„ä¸ªç ”ç©¶æ­¥éª¤"""
        try:
            # å¦‚æœè®¡åˆ’ä¸ºç©ºæˆ–ä¸åˆæ³•ï¼Œè¿”å›é»˜è®¤çš„ç ”ç©¶æ­¥éª¤
            if not plan:
                logger.warning("ç ”ç©¶è®¡åˆ’ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æ­¥éª¤")
                return [
                    {"title": "å¸‚åœºæ¦‚è§ˆ", "description": "åˆ†æå¸‚åœºè§„æ¨¡å’Œå¢é•¿è¶‹åŠ¿"}, 
                    {"title": "ç«äº‰åˆ†æ", "description": "è¯„ä¼°ä¸»è¦ç«äº‰å¯¹æ‰‹å’Œç«äº‰æ€åŠ¿"}, 
                    {"title": "å…³é”®é©±åŠ¨å› ç´ ", "description": "è¯„ä¼°å¸‚åœºæˆé•¿çš„ä¸»è¦é©±åŠ¨å› ç´ "},
                    {"title": "è¶‹åŠ¿å±•æœ›", "description": "åˆ†ææœªæ¥å‘å±•è¶‹åŠ¿å’Œæœºä¼š"}
                ]
                
            steps = []
            current_step = None
            
            for line in plan.split('\n'):
                line = line.strip()
                
                # å¦‚æœæ˜¯æ ‡é¢˜è¡Œï¼Œåˆ›å»ºä¸€ä¸ªæ–°æ­¥éª¤
                if line.startswith('##'):
                    title = line.replace('##', '').strip()
                    if current_step and current_step["title"] and current_step["description"]:
                        steps.append(current_step)
                    current_step = {"title": title, "description": ""}
                elif line.startswith('#'):
                    title = line.replace('#', '').strip()
                    if current_step and current_step["title"] and current_step["description"]:
                        steps.append(current_step)
                    current_step = {"title": title, "description": ""}
                # å¦‚æœæœ‰å½“å‰æ­¥éª¤ä¸”è¡Œä¸ä¸ºç©º
                elif current_step and line:
                    current_step["description"] += line + "\n"
            
            # æ·»åŠ æœ€åä¸€ä¸ªæ­¥éª¤
            if current_step and current_step["title"] and current_step["description"]:
                steps.append(current_step)
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç ”ç©¶æ­¥éª¤
            if not steps:
                logger.warning("æ— æ³•ä»ç ”ç©¶è®¡åˆ’ä¸­è§£æå‡ºæ­¥éª¤ï¼Œä½¿ç”¨é»˜è®¤æ­¥éª¤")
                return [
                    {"title": "å¸‚åœºæ¦‚è§ˆ", "description": "åˆ†æå¸‚åœºè§„æ¨¡å’Œå¢é•¿è¶‹åŠ¿"}, 
                    {"title": "ç«äº‰åˆ†æ", "description": "è¯„ä¼°ä¸»è¦ç«äº‰å¯¹æ‰‹å’Œç«äº‰æ€åŠ¿"}, 
                    {"title": "å…³é”®é©±åŠ¨å› ç´ ", "description": "è¯„ä¼°å¸‚åœºæˆé•¿çš„ä¸»è¦é©±åŠ¨å› ç´ "},
                    {"title": "è¶‹åŠ¿å±•æœ›", "description": "åˆ†ææœªæ¥å‘å±•è¶‹åŠ¿å’Œæœºä¼š"}
                ]
                
            logger.info(f"ä»ç ”ç©¶è®¡åˆ’ä¸­æˆåŠŸæå–äº†{len(steps)}ä¸ªç ”ç©¶æ­¥éª¤")
            return steps
        except Exception as e:
            logger.error(f"è§£æç ”ç©¶è®¡åˆ’æ—¶å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶è¿”å›é»˜è®¤æ­¥éª¤
            return [
                {"title": "å¸‚åœºæ¦‚è§ˆ", "description": "åˆ†æå¸‚åœºè§„æ¨¡å’Œå¢é•¿è¶‹åŠ¿"}, 
                {"title": "ç«äº‰åˆ†æ", "description": "è¯„ä¼°ä¸»è¦ç«äº‰å¯¹æ‰‹å’Œç«äº‰æ€åŠ¿"},
                {"title": "å…³é”®é©±åŠ¨å› ç´ ", "description": "è¯„ä¼°å¸‚åœºæˆé•¿çš„ä¸»è¦é©±åŠ¨å› ç´ "},
                {"title": "è¶‹åŠ¿å±•æœ›", "description": "åˆ†ææœªæ¥å‘å±•è¶‹åŠ¿å’Œæœºä¼š"}
            ]
            
    def _generate_step_search_queries(self, step_title, step_description):
        """ä¸ºç ”ç©¶æ­¥éª¤ç”Ÿæˆä¼˜åŒ–çš„æœç´¢æŸ¥è¯¢"""

        try:
            # ä½¿ç”¨ç ”ç©¶æ ‡é¢˜å’Œæè¿°ç”Ÿæˆç²¾å‡†æŸ¥è¯¢
            logger.info(f"ä¸ºç ”ç©¶æ­¥éª¤ '{step_title}' ç”Ÿæˆæœç´¢æŸ¥è¯¢")

            
            from app.services.siliconflow_service import siliconflow_service

            
            # ä½¿ç”¨ç®€æ´çš„æç¤ºç”Ÿæˆç‹¬ç‰¹æŸ¥è¯¢
            prompt = f"""è¯·ä¸ºä»¥ä¸‹ç ”ç©¶æ­¥éª¤ç”Ÿæˆ 3 ä¸ªç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ï¼Œä»¥è·å–æœ€æ–°ã€æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚è¯·ä»…è¿”å›æœç´¢æŸ¥è¯¢ï¼Œæ¯è¡Œä¸€ä¸ªï¼š

ç ”ç©¶æ­¥éª¤: {step_title}
æè¿°: {step_description}

æŸ¥è¯¢åº”è¯¥åŒ…å«ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„å…³é”®è¯å’Œæ—¶é—´èŒƒå›´ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„é—®å¥ã€‚"""

            
            # è°ƒç”¨ç¡…åŸºæµåŠ¨APIç”ŸæˆæŸ¥è¯¢
            search_queries_text = ""

            try:
                search_queries_text = siliconflow_service.generate_search_queries(prompt)

            except Exception as query_error:
                logger.warning(f"è°ƒç”¨æŸ¥è¯¢ç”ŸæˆæœåŠ¡å‡ºé”™: {str(query_error)}")

                # åˆ›å»ºé»˜è®¤æŸ¥è¯¢
                search_queries_text = f"{step_title}\n{step_title} æœ€æ–°æ•°æ®\n{step_title} åˆ†æ è¶‹åŠ¿"

            
            # åˆ†è¡Œå¹¶è¿‡æ»¤ç©ºè¡Œ
            queries = [q.strip() for q in search_queries_text.split('\n') if q.strip()]

            
            # è¿‡æ»¤æ‰å¯èƒ½çš„æ ‡é¢˜è¡Œå’ŒéæŸ¥è¯¢æ–‡æœ¬
            queries = [q for q in queries if not (q.startswith('#') or q.startswith('1. ') or len(q) > 100)]

            
            # ç¡®ä¿æŸ¥è¯¢åŒ…å«å…³é”®è¯
            if not any(step_title.lower() in q.lower() for q in queries) and queries:

                # åœ¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢å‰æ·»åŠ ä¸»é¢˜å…³é”®è¯
                queries[0] = f"{step_title} {queries[0]}"

            
            # ä¿è¯è¿”å›è‡³å°‘ä¸€ä¸ªæŸ¥è¯¢
            if not queries:

                # åˆ›å»ºä¸€ä¸ªç¬¦åˆç°ä»£æœç´¢å¼•æ“è§„åˆ™çš„æŸ¥è¯¢
                queries = [f"{step_title} ç ”ç©¶ æœ€æ–°", f"{step_title} æ•°æ® åˆ†æ"]

                
            logger.info(f"ç”Ÿæˆäº† {len(queries)} ä¸ªæœç´¢æŸ¥è¯¢: {queries}")

            return queries[:3]  # é™åˆ¶ä¸º3ä¸ªæŸ¥è¯¢ï¼Œä½¿æœç´¢æ›´åŠ ç²¾å‡†

            
        except Exception as e:

            logger.error(f"ç”Ÿæˆæœç´¢æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")

            # å¦‚æœå‡ºé”™ï¼Œè¿”å›åŸºæœ¬æŸ¥è¯¢
            return [f"{step_title} æœ€æ–°ç ”ç©¶", f"{step_title} æ•°æ®åˆ†æ"]

            
    def _generate_search_queries(self, topic, requirements):

        """åŸºäºä¸»é¢˜å’Œè¦æ±‚ç”Ÿæˆæœç´¢æŸ¥è¯¢"""

        # åˆå§‹åŒ–æŸ¥è¯¢åˆ—è¡¨
        queries = []
        
        # åŸºç¡€æŸ¥è¯¢ - ä¸»é¢˜æœ¬èº«
        queries.append(topic)
        
        # ç‰¹å®šé¢†åŸŸæŸ¥è¯¢
        if "æ±½è½¦" in topic or "ç”µåŠ¨æ±½è½¦" in topic or "æ–°èƒ½æº" in topic:
            queries.extend([
                f"{topic} å¸‚åœºè§„æ¨¡ æ•°æ®",
                f"{topic} è¡Œä¸šè¶‹åŠ¿åˆ†æ",
                f"{topic} é”€é‡æ’å"
            ])
            
            # å¦‚æœæ˜¯ç”µåŠ¨æ±½è½¦ï¼Œæ·»åŠ ä¸€äº›ç‰¹å®šæŸ¥è¯¢
            if "ç”µåŠ¨æ±½è½¦" in topic:
                queries.extend([
                    f"ä¸­å›½ç”µåŠ¨æ±½è½¦ è¡¥è´´æ”¿ç­–",
                    f"ä¸­å›½ç”µåŠ¨æ±½è½¦ å……ç”µåŸºç¡€è®¾æ–½"
                ])
        elif "å¸‚åœº" in topic or "åˆ†æ" in topic:
            queries.extend([
                f"{topic} è¡Œä¸šæŠ¥å‘Š",
                f"{topic} æ•°æ®ç»Ÿè®¡",
                f"{topic} å‘å±•å‰æ™¯"
            ])
        elif "æŠ€æœ¯" in topic or "åˆ›æ–°" in topic:
            queries.extend([
                f"{topic} æœ€æ–°è¿›å±•",
                f"{topic} ç ”ç©¶è¿›å±•",
                f"{topic} æ¡ˆä¾‹åˆ†æ"
            ])
        else:
            # é€šç”¨çš„æŸ¥è¯¢
            queries.extend([
                f"{topic} æ•°æ®åˆ†æ",
                f"{topic} è¡Œä¸šè¶‹åŠ¿",
                f"{topic} å‘å±•ç°çŠ¶"
            ])
        
        # å¦‚æœæœ‰ç‰¹å®šè¦æ±‚ï¼Œæ·»åŠ ç›¸å…³æŸ¥è¯¢
        if requirements:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šæ—¶é—´èŒƒå›´
            time_patterns = ["è¿‘äº”å¹´", "è¿‘ä¸‰å¹´", "è¿‘åå¹´", "2023", "2022", "2021", "2020"]
            for pattern in time_patterns:
                if pattern in requirements:
                    queries.append(f"{topic} {pattern} æ•°æ®")
                    break
            
            # å¦‚æœæœ‰å…·ä½“çš„åˆ†æéœ€æ±‚
            if "é¢„æµ‹" in requirements or "å±•æœ›" in requirements:
                queries.append(f"{topic} æœªæ¥é¢„æµ‹")
            
            if "ä¼ä¸š" in requirements or "å…¬å¸" in requirements or "å“ç‰Œ" in requirements:
                queries.append(f"{topic} ä¸»è¦ä¼ä¸š å¸‚åœºä»½é¢")
        
        # å»é™¤é‡å¤çš„æŸ¥è¯¢
        unique_queries = list(set(queries))
        
        # é™åˆ¶æŸ¥è¯¢æ•°é‡ï¼Œé¿å…è¿‡å¤š
        return unique_queries[:5]


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
research_service = ResearchService()
